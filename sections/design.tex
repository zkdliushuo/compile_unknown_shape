\section{System Design of \mysys}
\label{sec:design}

We propose \mysys, a highly accurate constant propagation framework that infers constant parameter values of kernels from deep learning frameworks, specifically PyTorch.
\mysys takes the ATen IR of the computation graph and the LLVM program of the operator as input.
We first generate the calling context for each operator invocation.
Starting from the entry function of the operator, \mysys performs context-sensitive interprocedural constant propagation, propagating constants through each basic block.
At the end of the analysis, the derived constant values for the concrete parameters of the kernel function are used to perform kernel specialization and optimization.

\begin{table}[htbp]
  \centering
  \small
  \renewcommand{\arraystretch}{1.1}
  \setlength{\tabcolsep}{6pt} % 标准表格稍微宽一点也没关系
  \caption{Abstract domains and definitions in \mysys.}
  \label{fig:abstract-domain}
  \begin{tabular}{ll}
    \hline
    \textbf{Domain} & \textbf{Notation} \\
    \hline
    Top-level Variable & $v \in \mathcal{V}$ \\
    Address-taken Var & $o \in \mathcal{O}$ \\
    Constant & $c := \text{Int} \mid \text{Float} \mid \text{FuncPtr}$ \\
    Pointer & $p := \langle \mathcal{B}, \delta \rangle$ \\
    Spec Value & $sv := c \mid p \mid \top \mid \bot$ \\
    Environment & $\mathbb{E} := \mathcal{V} \mapsto \mathcal{SV}$ \\
    Store & $\mathbb{S} := \mathcal{O} \mapsto \mathcal{SV}$ \\
    Calling Context & $\mathbb{C} := (\mathbb{E}, \mathbb{S})$ \\
    \hline
  \end{tabular}
\end{table}

\subsection{Definitions}\label{sec:design:definitions}

To formally describe our analysis, we define the abstract domains and symbols used in \mysys, as summarized in \autoref{fig:abstract-domain}.

\paragraph{Variables and Values.}
We classify variables into two categories: \kw{top-level variables} ($v \in \mathcal{V}$) and \kw{address-taken variables} ($o \in \mathcal{O}$).
A \kw{top-level variable} $v$ corresponds to an SSA (Static Single Assignment) value in LLVM IR, representing a virtual register defined by an instruction or a function argument.
An \kw{address-taken variable} $o$ represents an abstract memory object, such as a stack allocation (\texttt{alloca}) or a global variable, whose address can be manipulated.

The analysis state of these variables is represented by a \kw{specialization value} ($sv \in \mathcal{SV}$).
An $sv$ represents the abstract lattice value of a particular instruction or memory location.
The domain $\mathcal{SV}$ forms a lattice containing the following elements:
\begin{itemize}
    \item \textbf{Top ($\top$):} Represents an undefined or uninitialized state (identity element for the merge operation).
    \item \textbf{Bottom ($\bot$):} Represents an unknown or overdefined state (result of conflicting values).
    \item \textbf{Constant ($c$):} A concrete value, which can be an integer scalar, a floating-point number, or a function pointer.
    \item \textbf{Abstract Pointer ($p$):} Represented as a pair $\langle \mathcal{B}, \delta \rangle$.
    Here, $\mathcal{B} \subseteq \mathcal{O}$ is a set of potential base memory objects pointed to.
    $\delta$ represents the offset from the base, which can be a concrete integer or $\bot$ (if the offset is unknown).
\end{itemize}

\paragraph{Context and State.}
We define the program state using an \kw{Environment} $\mathbb{E}$ and a \kw{Memory Store} $\mathbb{S}$.
The Environment $\mathbb{E}: \mathcal{V} \mapsto \mathcal{SV}$ maps top-level variables to their specialization values, tracking the states of virtual registers.
The Memory Store $\mathbb{S}: \mathcal{O} \mapsto \mathcal{SV}$ maps address-taken variables (memory objects) to their stored values, modeling the heap and stack contents.
Consequently, a \kw{Calling Context} $\mathbb{C}$ is defined as a tuple $(\mathbb{E}_{entry}, \mathbb{S}_{entry})$, representing the initial state upon entering a function.
Specifically, $\mathbb{C}$ captures the specialized arguments: scalar parameters are mapped within $\mathbb{E}_{entry}$, while memory contents accessible via pointer parameters are initialized in $\mathbb{S}_{entry}$.

\subsection{Calling Context Generation for C++ Operators}\label{sec:design:context_construction}

\begin{figure}[htbp]
  \centering
  \includegraphics[width=\linewidth]{figures/sys-design/context-generation-through-pybind.png}
  \caption{Overview of context generation through PyBind in \mysys. This figure illustrates the workflow for reconstructing the bit-level initial state of C++ operators. In the showed memory layout, dashed arrows denote pointer/reference relationships between objects, while solid arrows denote structural field-containment (i.e., one aggregate type embedding another as a member field). Elements with the same background shading denote the same underlying function or class across different stages. The suffix "\_1" of \texttt{add\_1} denotes the first \texttt{add} operator in the model and distinguishes different occurrences of the same operator kind.}
  \Description{A diagram showing the workflow for reconstructing the bit-level initial state of C++ operators, including static analysis, trace analysis, and context synthesis. In the Memory layout subfigure, dashed arrows denote pointer/reference relationships between objects, while solid arrows denote structural field-containment (one aggregate embedding another as a member). Elements with the same background shading denote the same underlying function or class across different stages.}
  \label{fig:context_construction}
\end{figure}

\autoref{fig:context_construction} illustrates the overall workflow for reconstructing the bit-level initial state ($\mathbb{C}_{init}$) of C++ operators. 
The workflow bridges the gap between high-level Python execution and low-level C++ memory states through a hybrid approach.
As shown in \autoref{fig:context_construction}, the context generation module of \mysys consists of three core components highlighted with a \textbf{green background}, namely \textbf{Static Analysis}, \textbf{Trace Analysis}, and \textbf{Context Synthesis}. 
In the figure, elements with identical background shading refer to the same underlying function or class, consistently tracked across the different stages of the pipeline.
The process is divided into an offline preparation phase and an online synthesis phase.

\paragraph{Offline phase: static analysis of binding APIs and memory layout}

The offline phase (top of \autoref{fig:context_construction}) builds a comprehensive knowledge base of the codes of C++ operator library.
We employ a \textbf{static analysis} component (implemented based on Clang) to scan the library source code.
This module produces two key outputs:
\begin{itemize}
  \item \textbf{C++ Operator Metadata}: It locates Python–C/C++ bindings (e.g., mapping Python’s \texttt{add} to its C++ implementation) and records the corresponding function signatures.
  \item \textbf{Memory Layout of C++ Types}: It recursively parses the AST to recover concrete memory layouts. 
  For example, for the \texttt{Tensor} type, it infers a pointer to \texttt{TensorImpl}, which in turn contains nested structures such as \texttt{sizes} (within \texttt{std::vector<int>}).
\end{itemize}

\paragraph{Online phase: trace analysis and context synthesis}

The online phase (bottom of \autoref{fig:context_construction}) captures runtime information from the DL model to instantiate the context.

\textbf{Trace analysis.}
During model execution (e.g., \texttt{torch.add(a, b, ...)}), we invoke the \textbf{trace analysis} component (built on top of the tracing mechanism of compilers such as Inductor) to inspect the execution graph.
Unlike standard execution, this stage performs symbolic execution to preserve information about symbolic shapes.
For example, as illustrated in \autoref{fig:context_construction}, the input script marks tensor \texttt{b} as dynamic via \texttt{mark\_dynamic}.
Consequently, the framework’s runtime knows that the first dimension of \texttt{a} is a concrete constant \texttt{4} (from the Python layer), whereas the corresponding dimension of \texttt{b} is symbolic (unknown at compile time, denoted as ?) as indicated by the framework’s symbolic engine.

\textbf{Context synthesis.}
Finally, the \textbf{context synthesis} module combines the offline memory-layout information with the online argument values and produces the initial calling context $\mathbb{C}_{init} = (\mathbb{E}, \mathbb{S})$ for each C++ operator (e.g., \texttt{add\_1} in \autoref{fig:context_construction}).
Given the traced Python-level arguments, it applies a set of predefined \textbf{instantiation rules} that describe how to allocate abstract objects and initialize their fields in the environment $\mathbb{E}$ and store $\mathbb{S}$.
During this process, the synthesizer reconstructs pointer chains between abstract objects (e.g., $o_{t} \rightarrow o_{impl} \rightarrow o_{data}$) and fills the corresponding abstract memory locations.

The synthesis explicitly preserves the uncertainty observed in the trace.
For each field, if the traced value is a concrete constant (such as a static dimension \texttt{4}), the corresponding address in $\mathbb{S}$ is initialized with a constant specialization value.
If the value is symbolic or otherwise unknown at compile time, the rule writes $\top$ to that address, representing an “unknown but live” specialization value in our abstract domain.
This guarantees that the constructed $\mathbb{C}_{init}$ is sound for subsequent static analysis.

As a concrete example, consider the instantiation rule \textsc{[Tensor]} for a tensor argument.
Given a top-level variable $v$, a pointer to the tensor, and its corresponding traced shape list $L = [d_0, \dots, d_{n-1}]$ (where each $d_k$ may be a constant or a symbolic dimension), the rule allocates fresh abstract objects $o_t$, $o_{impl}$, and $o_{data}$, and updates the environment and store as specified in the inference rule.
Here, $o_t$ models the \texttt{Tensor} object, $o_{impl}$ models the internal \texttt{TensorImpl}, and $o_{data}$ models the contiguous buffer storing the tensor sizes (e.g., the internal array of \texttt{std::vector<int>}).
The offset $\delta_{sz}$ denotes the position of the \texttt{sizes} field within \texttt{TensorImpl}, and $w$ is the stride (in bytes) of one size element.
The helper function $\alpha$ maps a concrete dimension $d_k$ to a constant specialization value in $\mathcal{SV}$, and maps a symbolic $d_k$ to $\top$, capturing that the value must be treated as unknown by the analysis.
This rule-based instantiation mechanism can generalize to other framework-specific types and provide the foundation for constructing precise and sound C++ calling contexts in \mysys.

\begin{equation}
  \textsc{[Tensor]} \quad
  \frac{
    \begin{aligned}
      o_{t}&, o_{impl}, o_{data}~ \text{ are fresh} \\
      L &= [d_0, \dots, d_{n-1}] \\
      \mathbb{E}'& = \mathbb{E}[v \mapsto \addr{o_{t}}{\mathbf{0}}]
    \end{aligned}
    \qquad
    % Part 3: Store Update (Right)
    \mathbb{S}' = \mathbb{S} \left[ 
      \begin{aligned}
        \addr{o_{t}}{\mathbf{0}} & \mapsto \addr{o_{impl}}{\mathbf{0}}, \\
        \addr{o_{impl}}{\delta_{sz}} & \mapsto \addr{o_{data}}{\mathbf{0}}, \\
        \addr{o_{impl}}{\delta_{sz} + \delta_{cap}} & \mapsto n, \\
        \forall k \in [0, n).\; \addr{o_{data}}{k \cdot w} & \mapsto \alpha(d_k)
      \end{aligned}
    \right]
  }{
    % Conclusion
    \langle \textsc{Tensor}(v, L), \compstate{\mathbb{E}}{\mathbb{S}} \rangle \longrightarrow \compstate{\mathbb{E}'}{\mathbb{S}'}
  }
\end{equation}

\textbf{Why predefine rules for C++ calling-context synthesis?}
Although trace analysis preserves rich symbolic information for Python-level arguments (e.g., symbolic tensor dimensions), this information is disconnected from the concrete memory layout used by C++ operator implementations.
In particular, there is no automatically available mapping from a framework-level symbolic variable to its exact byte offset and container object in the C++ layout (e.g., an element of \texttt{TensorImpl::sizes\_} inside a nested \texttt{std::vector<int>}).
Reconstructing such a mapping would require precisely tracking how values flow from the Python runtime into C++ auxiliary buffers.
These behaviors are dispersed across the Python–C/C++ boundary and lose high-level semantics, making a fully automatic and sound "Python runtime values $\leftrightarrow$ C++ field offset" mapping impractical.

Therefore, \mysys adopts a pragmatic design: for a small set of core C++ types (such as \texttt{Tensor}), we manually define instantiation rules that specify how Python-level argument values (including symbolic dimensions) are embedded into the C++ memory state.
In practice, the parameter types of C++ operators are very limited—primarily \texttt{Tensor}, several container types (e.g., \texttt{vector<T>}), and scalar types—so a small number of hand-written rules suffice to support a wide range of operators across libraries.
These core abstractions are also highly stable and rarely change, making the rule set robust and low-maintenance.
Operator developers provide these rules, and the context synthesis module interprets them to construct $\mathbb{C}_{init}$ in a sound and repeatable way.

\subsection{Identify Early Return Pattern}\label{sec:design:early-return}

\input{algorithm/early-return}

The early-return path bypasses the normal execution path, and these two paths often join at the function's ending block. 
At join points, merging values from both paths results in losing specialized constant information. 
Identifying these early-return paths allows avoiding merging value information on these paths, thereby preserving only the constant values produced on the normal execution path.
To this end, we introduce \autoref{algo:runtime-shape-check-detection} to identify and label early-return edges in the control-flow graph.
Once identified, the subsequent constant propagation pass excludes these edges, effectively pruning the error handling paths from the data-flow analysis.

At a high level, our approach relies on a reverse data-flow analysis rooted at the function's exit block. 
The fundamental principle is to trace the provenance of all values reaching the return instructions. 
In LLVM IR, a return value originates from either a compile-time constant or the result of a function call (potentially merged via \texttt{phi} nodes). 
By semantically evaluating these value sources against known error status codes, we can deduce whether a specific execution path terminates in a failure state. 
If a value source represents an error condition, the control flow edge leading to this source is identified as an early-return path.

We first define two sets of status codes, $\mathcal{E}$ and $\mathcal{S}$, representing the error and success states, respectively. 
These sets consist of compile-time constants manually configured based on the target operator library specifications (e.g., $\mathcal{S}=\{0\}$ and $\mathcal{E}=\{-1\}$).
\autoref{algo:runtime-shape-check-detection} starts by initializing a worklist with the return values from the function's exit block.
It employs the helper function \texttt{GetPhiOperand} to recursively trace the data flow: if a value corresponds to a \texttt{phi} node, its incoming operands are added to the worklist to resolve the merge logic; otherwise, the value is identified as a concrete \texttt{value source} originating from a specific basic block.

To identify local early-return edges, the algorithm analyzes the control dependencies of the identified value source by traversing the dominator tree.
It primarily looks for conditional branches that guard the execution of the return block.
If a branch compares a status variable against a constant in $\mathcal{S}$ or $\mathcal{E}$, the algorithm identifies the failure path based on the comparison logic (Patterns 1 \& 2).
However, even if no such status check is found (e.g., a local arithmetic check), if the return value source itself is a constant belonging to $\mathcal{E}$, the algorithm directly marks the path as an early return (Pattern 4).
We detail the detection process using four common patterns found in operator libraries, as illustrated in \autoref{fig:early-return-patterns}.

\begin{figure}[ht]
  \centering
  % Row 1: Pattern 1 & 2
  \begin{minipage}{0.25\textwidth}
      \centering
      % 顶格写
      \begin{lstlisting}[language=llvm, basicstyle=\scriptsize\ttfamily, frame=single, numbers=none, breaklines=true, xleftmargin=2pt, xrightmargin=2pt]
  %ret = call @check
  %c = icmp ne %ret, 0
  br %c, %exit, %nxt
exit: ; Joined block
  %v = phi i32 [%ret, %pred], ...
  ret i32 %v
      \end{lstlisting}
      \textbf{(a) Pass-through}
  \end{minipage}
  \hfill
  \begin{minipage}{0.25\textwidth}
      \centering
      % 顶格写
      \begin{lstlisting}[language=llvm, basicstyle=\scriptsize\ttfamily, frame=single, numbers=none, breaklines=true, xleftmargin=2pt, xrightmargin=2pt]
  %ret = call @check
  %c = icmp ne %ret, 0
  br %c, %exit, %nxt
exit: ; Joined block
  %v = phi i32 [-1, %pred], ...
  ret i32 %v
      \end{lstlisting}
      \textbf{(b) Explicit Error}
  \end{minipage}
  \hfill
  \begin{minipage}{0.25\textwidth}
      \centering
      % 顶格写
      \begin{lstlisting}[language=llvm, basicstyle=\scriptsize\ttfamily, frame=single, numbers=none, breaklines=true, xleftmargin=2pt, xrightmargin=2pt]
  %rem = srem i32 %s, 32
  %c = icmp ne i32 %rem, 0
  br %c, %exit, %nxt
exit: ; Joined block
  %v = phi i32 [-1, %pred], ...
  ret i32 %v
      \end{lstlisting}
      \textbf{(c) Local Constant Error}
  \end{minipage}
  \hfill
  % Row 2: Pattern 3 & 4
  \begin{minipage}{0.2\textwidth}
      \centering
      % 顶格写
      \begin{lstlisting}[language=llvm, basicstyle=\scriptsize\ttfamily, frame=single, numbers=none, breaklines=true, xleftmargin=2pt, xrightmargin=2pt]
%ret = call @check
; Direct return
; No local check
ret i32 %ret
      \end{lstlisting}
      \textbf{(d) Tail Call}
  \end{minipage}

  \Description{Simplified LLVM IR examples showing four common early return patterns: Pass-through, Explicit Error, Local Constant Error, and Tail Call.}
  \caption{Simplified LLVM IR examples of common early return patterns handled by Algorithm~\ref{algo:runtime-shape-check-detection}}
  \label{fig:early-return-patterns}
\end{figure}

\textbf{Pass-through.} 
As shown in \autoref{fig:early-return-patterns}(a), the code checks a status variable returned by a subroutine and returns it directly upon failure.
The algorithm traces the return value \texttt{\%v} back to its source, \texttt{\%ret}.
By analyzing the dominator tree, it finds the predecessor's branch condition \texttt{\%ret != 0}.
Since this implies the edge to \texttt{exit} is an error path, and the return value matches the checked variable, the incoming edge is marked as an \texttt{Early-Return}.
Subsequently, it recursively invokes \texttt{RunOnFunction} on the callee \texttt{@check}.

\textbf{Explicit Error.} 
In \autoref{fig:early-return-patterns}(b), the code checks a status variable but explicitly returns a constant error code.
Here, the value source is the constant \texttt{-1}.
The algorithm verifies that \texttt{-1} belongs to $\mathcal{E}$ and detects that the guarding branch targets the \texttt{exit} block upon failure.
Although the returned value differs from the checked variable, the semantic link via control dependency allows the algorithm to mark the edge as \texttt{Early-Return} and recursively analyze the callee.

\textbf{Local Constant Error.}
\autoref{fig:early-return-patterns}(c) illustrates a case where a local shape check (e.g., alignment check \texttt{s \% 32 != 0}) leads to an immediate error return.
The value source is the constant \texttt{-1}.
In this case, even if the algorithm does not find a status-code-based check in the dominator tree (since the check is arithmetic), it identifies that the return value \texttt{-1} belongs to the error set $\mathcal{E}$.
Consequently, the algorithm treats the path originating from this value source as a confirmed failure path and marks the edge leading to the exit block as \texttt{Early-Return}.

\textbf{Tail Call.}
\autoref{fig:early-return-patterns}(d) shows a tail call pattern with no local checks.
The return value source is \texttt{\%ret}.
Since no guarding conditional branch is found, no local edge is marked.
However, identifying that the return value comes from a call instruction allows the algorithm to recursively apply the analysis to \texttt{@check}, ensuring interprocedural soundness.


Complementing the local identification, the inter-procedural analysis is essential as status codes typically originate from nested subroutine calls.
Therefore, whenever the algorithm identifies a value source associated with a function call—whether it matches the failure branch in Patterns 1 and 2, or is a direct tail call in Pattern 3—it identifies the callee function and recursively invokes \texttt{RunOnFunction}.
This ensures that the "early return" property is correctly propagated from the innermost shape check functions up to the entry points of the operator.


\subsection{Information Propagation on Host-Side Programs and Device Kernel Specialization}\label{sec:design:propagation}

Our primary objective is to optimize the performance of device kernel functions. 
To this end, \mysys serves two distinct roles:
(1) For host-side functions, it propagates precise semantic information (pointer targets, function objects) to kernel launch points.
(2) For device-side functions, it performs kernel specialization via parameter substitution and constant folding based on the propagated context.

\subsubsection{Inter-Procedural Information Propagation for Host-Side Programs}

\mysys employs a unified inter-procedural analysis framework integrating pointer analysis, function object propagation, and scalar constant propagation.
Operating on the CFG, the analysis maintains a symbolic environment $\mathbb{E}$ and a flow-sensitive memory store $\mathbb{S}$.
We detail the handling of key program constructs below.

\paragraph{Pointer Arithmetic and Alias Analysis}
We represent a pointer value as a pair $\langle \mathcal{B}, \delta \rangle$. 
For pointer arithmetic (e.g., \texttt{getelementptr}), we update the offset $\delta$ while preserving the base set $\mathcal{B}$.
To balance precision and overhead, we bound $|\mathcal{B}| \le 5$, demoting the base to \texttt{Unknown} if this limit is exceeded.
Function pointers are similarly propagated to support indirect calls.
To refine alias analysis when bases are unknown, we leverage LLVM's Type-Based Alias Analysis (TBAA) metadata to restrict the scope of potential memory conflicts to type-compatible objects.

\paragraph{Memory Operations}
The memory store $\mathbb{S}$ is updated and accessed by three primary instructions.
Allocation instructions introduce new abstract locations into $\mathbb{S}$, managed with context-sensitive modeling.
Store instructions update the flow-sensitive store $\mathbb{S}$ local to the current basic block: writing to a pointer with a deterministic base performs a \kw{strong update} (replacement), whereas writing to an unknown base or offset triggers a \kw{weak update} (conservative invalidation/merge).
Load instructions simply retrieve the current specialization value from $\mathbb{S}$ corresponding to the accessed address.

\paragraph{Context-Sensitive Function Calls}
We employ a context-sensitive approach akin to abstract interpretation.
Each call site generates a specialized calling context based on the actual arguments and the current store $\mathbb{S}$.
The algorithm recursively analyzes the callee, using memoization to cache results for identical contexts.
Recursion is handled by tracking the call stack and returning a conservative "top" value ($\top$) upon detecting cycles, ensuring termination.

\paragraph{Control Flow Processing}
We adopt a hybrid strategy for loops, prioritizing a \kw{Per-Iteration Analysis} that simulates execution iteration by iteration.
If loop conditions become non-constant, the analysis falls back to a \kw{Maximal Fixed-Point (MFP)} iteration.
Within these modes, conditional branches determine edge liveness: if a condition evaluates to a constant, the non-taken edge is marked \texttt{Inactive}; otherwise, both branches are marked \texttt{Active}.
This liveness information is critical for pruning unreachable paths during propagation.

\paragraph{Context Merging and Early-Return Integration}
At control flow convergence points, we merge the incoming stores $\mathbb{S}$ from all \texttt{Active} predecessors and merge incoming specialization values for \texttt{PHI} instructions.
The merging applies standard lattice operations.
Crucially, this step integrates with the optimization described in \cref{sec:design:early-return}.
Any predecessor edge marked as an \texttt{early-return} path, or determined to be unreachable by the branch analysis, is treated as \texttt{Inactive}.
Consequently, the memory states and values from these inactive blocks are excluded entirely from the merge operation.
This prevents the pollution of the analysis state by imprecise or error-handling logic, significantly improving the precision of the propagated information at join points. stores $\mathbb{S}$ from all predecessors.

\subsubsection{Device Kernel Specialization}

Once the inter-procedural analysis reaches a kernel launch point, \mysys leverages the propagated context to perform kernel specialization. 
We extract concrete values from the host-side environment $\mathbb{E}$ and memory store $\mathbb{S}$ to replace the corresponding kernel parameters. 
By substituting variable accesses with constants, we resolve data dependencies and control flow decisions at compile time, transforming the generic kernel into a highly optimized, context-specific version.

For kernels invoked via driver launch APIs, the mapping from host arguments to device parameters is indirect. 
We construct the specialization context by extracting the target kernel function object from the API call. 
Using predefined ABI (Application Binary Interface) rules, we map the launch API's argument array to the kernel's formal parameters, ensuring that the constant values identified on the host side are correctly bound to the device function's context.

Following parameter substitution, we employ a tailored pipeline of standard LLVM optimization passes to exploit the newly exposed optimization opportunities. 
As implemented in our pass manager, this pipeline iteratively applies \texttt{Interprocedural Sparse Conditional Constant Propagation (IPSCCP)} and \texttt{Instruction Combining} to fold computations involving the new constants. 
Furthermore, we execute aggressive loop transformations—including \texttt{Loop Unrolling} and \texttt{Loop Invariant Code Motion (LICM)}, alongside \texttt{Global Value Numbering (GVN)} and \texttt{CFG Simplification}. 
These passes work in concert to eliminate dead code, simplify control flow, and remove redundancies, significantly reducing the runtime overhead of the specialized kernel. 