\section{Introduction}\label{sec:intro}

% 随着深度学习的快速发展，诸如 Llama 3、DeepSeek 和 Qwen 等大型模型不断涌现并在众多任务中表现出色。
% 为了加速大模型的训练和推理并提供庞大的算力支撑，许多公司开发了各自的领域专用架构（DSA），包括英伟达 GPU、华为 Ascend NPU 和谷歌 TPU。
% 作为这些芯片的代表之一，Ascend NPU 已被广泛应用于支持各类有影响力的模型，例如 Qwen 和 DeepSeek 系列，并取得了高性能和低功耗的优势。
With the rapid evolution of deep learning, numerous large models have emerged and demonstrated exceptional performance across various tasks, such as Llama 3, DeepSeek, and Qwen.
To accelerate the training and inference of these large models and provide substantial computational support, many companies have developed their own Domain-Specific Architectures (DSAs), including NVIDIA GPUs, Huawei Ascend NPUs, and Google TPUs.
As a representative of these chips, the Ascend NPU has been extensively deployed to support various influential models, such as the Qwen and DeepSeek series, achieving high performance with low power consumption.

% 相较于通用 GPU，Ascend 的特点是引入了几种额外的可编程硬件部件，以高效支撑不同类型的计算：
% 1）计算部件，包括处理控制流、指令分发和标量计算的 scalar unit，以及分别处理向量化和矩阵操作的 Vector 和 Cube Unit。
% 2）多种存储缓冲区和数据搬运部件：包括面向 Cube Unit 的 L0 A/B/C buffer，以及面向 Vector Unit 的 Unified buffer。这些存储部件之间的数据搬运方式高度灵活。
Compared to general-purpose GPUs, Ascend introduces several additional programmable hardware components to efficiently support distinct types of computations:
1) Computational components, including the \textbf{scalar unit} for handling control flow, instruction dispatch, and scalar data computations, as well as the \textbf{Vector} and \textbf{Cube Units} for processing vectorized and matrix operations, respectively.
2) Memory hierarchy and data transfer components, such as L0 A/B/C buffers for the Cube Unit and a Unified Buffer for the Vector Unit, featuring flexible data transfer mechanisms between these storage components.

% 然而，开发高性能 Ascend 算子面临着其他 DSA 中不常见的挑战。
% 为了处理大语言模型中的动态形状（例如 batch 内变化的 query 长度和 KV cache），Ascend 算子开发者需要定义大量的参数来调度算子以适应运行时形状，我们将这些参数统称为“调度参数”。
% 为了实现最佳性能，这些调度参数（如核间并行度、循环切分策略、缓冲区数量等）连同算子属性（如注意力头数）通常被定义为核函数的形式参数。
% 这导致 Ascend 核函数拥有极多的参数。例如，用于 LLM 自回归解码的高效融合算子 Flash Decoding，其 Ascend 实现拥有超过 200 个调度参数。
However, developing high-performance Ascend kernels introduces unique challenges not typically encountered in other DSAs.
Modern deep learning models involve dynamic shapes where input tensor dimensions (e.g., query and KV cache lengths for Large Language Models) vary at runtime.
To handle these dynamics and mitigate load imbalance, kernel developers must define a substantial number of parameters, e.g., inter-core parallelism, loop tiling strategies, and buffer counts, to schedule the kernel adaptively.
These schedule parameters, along with shape parameters (e.g., actual sequence length) and operator attributes (e.g., is causal masked), are defined as formal parameters of the kernel functions.
\autoref{lst:add_kernel_with_formal_param} shows an implementation of the \kw{add} operator, where \kw{s} and \kw{t} are formal parameters of the \kw{kernel} function.


\begin{figure}[htbp]
    \centering
    \begin{minipage}{0.48\textwidth}
    \begin{lstlisting}[basicstyle=\ttfamily\footnotesize, frame=single]
void kernel(float* A, float* B, float* C, int s, int t) {
  for (int i = 0; i < s; i += t)
    for (int j = 0; j < t; ++j)
      int idx = i + j;
      if(idx < s) C[idx] = A[idx] + B[idx];
}
    \end{lstlisting}
    \end{minipage}
\hfill
    \begin{minipage}{0.48\textwidth}
    \begin{lstlisting}[basicstyle=\ttfamily\footnotesize, frame=single, firstnumber=7]
status add(Tensor& A, Tensor& B, Tensor& C) {
  int s = A.size(0), t = 0;
  if (tiling(s, t) != SUCCESS) 
    return ERROR;
  return kernel(A.ptr, B.ptr, C.ptr, s, t);
}
    \end{lstlisting}
    \end{minipage}
    \caption{Example of the add operator. The \kw{kernel} function has two parameters \kw{s} and \kw{t}, representing the size of the input tensors and the tiling factor, respectively. 
    The \kw{tiling} function computes the tiling factor based on the input size. The \kw{add} function serves as the operator interface, extracting input sizes and invoking the kernel with the appropriate parameters. 
    For simplicity, the definition of the \kw{tiling} function is shown in \autoref{lst:early_return_code}. 
    \texttt{Tensor} is a data structure representing a multi-dimensional array adopted in deep learning frameworks, with a method \texttt{size} that retrieves the size of a specific dimension.}
    \label{lst:add_kernel_with_formal_param}
\end{figure}


% 过多的核函数参数会导致 Ascend 遭遇“标量瓶颈”（Scalar Bottleneck）。
% 这一瓶颈主要源于两方面原因：
% 1. 有限的通用寄存器导致频繁的寄存器溢出到慢速的局部内存。
% 2. 变量参数阻碍了冗余指令（如分支跳转和地址计算）的消除，导致代码膨胀并增加指令缓存（I-cache）未命中。
% 这些标量延迟阻塞了向其他部件（Vector/Cube）的指令分发，严重降低了算子性能。
When the implementation is complex, kernels often suffer from an excessive number of parameters.
Excessive kernel parameters may expose the device to a critical performance issue known as the \textbf{Scalar Bottleneck}.
The root cause is twofold.
First, the limited register file size (e.g., only 32 general-purpose registers) forces the scalar unit to frequently spill intermediate variables to high-latency local memory.
Second, variable parameters prevent the compiler from optimizing away redundant instructions (e.g., conditional branches) and constant folding, increasing instruction cache (I-cache) misses and execution cycles of the scalar unit.
Since other hardware components units rely on the scalar unit for instruction dispatch, these scalar latencies cause severe pipeline stalls, becoming a primary performance degradation for kernels.

\begin{figure}[htbp]
    \centering
\includegraphics[width=\linewidth]{figures/motivation/combined_analysis.pdf}
    \caption{Some representative operators involves a number of parameters, meanwhile the operators shows scalar bound (scalar units are busy for over 60\% cycles) and significant instruction cache miss.
    % D-Attn and P-Attn represent Flash Attention operator at  the decoding and prefill phase.  
    The detailed operators information are shown in \autoref{tab:dynamic_operators}.}
    \label{lst:invariable_params_scalar_ratio}
\end{figure}


% 为了证明这一点，我们对 CANNDev 和 CANN OPS ADV 算子库中的算子进行了 Profiling。
% 结果表明，Ascend 核函数性能对参数数量高度敏感。
% 进一步分析发现，一旦模型超参数（如 hidden size）和硬件配置固定，绝大多数核函数参数实际上是编译期常量。
% 这揭示了一个潜在的加速机会：识别这些编译期常量参数，并将其替换为常量值，从而生成针对特定模型和硬件特化的核函数。
To demonstrate this impact, we profiled various operators from widely used Ascend libraries (ops-nn and ops-transformer).
Our analysis reveals that kernel performance is highly sensitive to the parameter count, with scalar units often becoming overwhelmed.
Crucially, we observed that once model hyper-parameters (e.g., hidden size) and hardware configurations are fixed, the majority of these kernel parameters become compile-time constants.
\autoref{lst:invariable_params_scalar_ratio} shows some representative operators whose parameters are mostly invariable under fixed model and hardware settings, while the operators suffer from severe scalar bottleneck and instruction cache miss.
This reveals a significant optimization opportunity: identifying and replacing these parameters with constant values at compile time to generate specialized kernels tailored for specific models and hardware.

% 据我们所知，现有的算子特化方法主要有两种：
% 1) Ahead-of-Time (AoT)：预编译少量特定参数的 kernel。但这会导致严重的代码膨胀，且无法覆盖所有动态形状的组合。
% 2) Just-In-Time (JIT)：在运行时确定参数值并编译。但这引入了不可忽视的运行时编译和 wrapper 执行开销，不适合工业级部署。
% 因此，我们需要一种既能利用静态形状信息，又不需要运行时编译开销的自动常量特化框架。
To the best of our knowledge, existing kernel specialization methods fall into two categories:
1) Ahead-of-Time (AoT) approaches \cite{ye2025flashinfer,nvidia2021cublas} manually precompile kernels for a limited set of parameter values. However, this leads to severe code bloat and cannot exhaustively cover the combinatorial space of dynamic shapes.
2) Just-In-Time (JIT) approaches \cite{chenTVMAutomatedEndtoend2018,tillet2019triton,zheng2020ansor} determine parameter values and compile kernels at runtime. This introduces significant CPU overhead for compilation and wrapper execution, making it less suitable for latency-critical industrial deployments where precompiled binaries are preferred.
Therefore, there is a compelling need for an automated framework that can leverage compile-time constant information derived from input shapes without incurring runtime overhead.

% 基于算子库主要用 C++ 开发的事实，我们提出 \mysys，一个自动算子特化框架。
% \mysys 的工作原理是从深度学习框架导出算子的输入输出上下文，其中记录了常量和变量的精确信息。
% 在此导出的上下文之上，我们执行全程序的常量传播。
% 我们采用基于抽象解释的方法，在格（Lattice）上计算并维护程序中每个变量（包括普通变量和被取地址的变量）的值状态。
Based on the fact that operator libraries are predominantly developed in C++, we propose \mysys, an automatic kernel specialization framework.
At a high level, \mysys operates by exporting the input and output contexts of operators directly from the deep learning framework such as PyTorch, which record precise information regarding both constants and symbolic variables.
Upon these exported contexts, we perform whole-program constant propagation.
Adopting an abstract interpretation-based approach, we calculate and maintain the value state of every variable, including both standard scalar variables and address-taken memory locations, on a lattice throughout the program execution path.

% 然而，实现这样一个框架面临着两个不可避免的核心挑战，我们分别提出了解决方案：
% 1. 跨语言语义 Gap：Python 层的语义在调用 C++ 二进制时丢失。我们通过上下文重建（Context Reconstruction）解决，即合成与 C++ 兼容的内存布局。
% 2. 动态形状检查模式：防御性检查导致分析精度下降。我们通过 Early Return 路径识别（Early Return Path Identification）解决，识别并剪除不可行的错误路径。
However, implementing such a framework faces two inevitable challenges, which we address with targeted solutions:
\begin{enumerate}
    \item \textbf{Cross-Language Semantic Gap:} The semantic disconnect between the high-level framework (Python) and the low-level operator library (C++) hinders direct analysis. We address this via \textbf{Context Reconstruction}, which involves synthesizing a bit-level memory context compatible with the C++ binary from the high-level framework information.
    \item \textbf{Patterns of Dynamic Shape Checks:} Defensive checks for dynamic shapes in operator libraries often lead to precision loss in static analysis. We tackle this through \textbf{Early Return Path Identification}, which detects and prunes infeasible error handling paths through the whole program to maintain analysis precision.
\end{enumerate}

%sxy% 介绍两项核心挑战的部分可能需要更详细的介绍，现在跨度有点大。我看到你在Background和challenge章节中有详细分析，但是我感觉在intro中需要适当详细帮助理解。

% 大量的实验表明，\mysys 显著降低了推理时延，尤其是标量计算开销。
Extensive experiments demonstrate that \mysys significantly reduces inference latency, particularly scalar computation overhead, effectively mitigating the scalar bottleneck.

%sxy% 可以在intro的结尾更详细的介绍实验和成效，给出具体的数值。