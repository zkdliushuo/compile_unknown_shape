\section{Introduction}\label{sec:intro}

% 随着深度学习的发展，许多大型模型不断涌现并在众多任务中表现出色，如 Llama 3、DeepSeek、Qwen 和 OpenSora等等。
% 为了加速大模型的训练和推理，更好地提供庞大的算力支撑，许多公司开发了各自的领域专用架构（DSA），包括英伟达GPU、华为 Ascend NPU、谷歌 TPU 和寒武纪 MLU 等。
% 作为这些芯片的代表之一，Ascend NPU 目前已经广泛支持了各类有影响力的模型，例如Qwen、DeepSeek系列的模型，Ascend 取得了高性能和低功耗。

With the development of deep learning, many large models have emerged and performed well in various tasks, such as Llama 3, DeepSeek, and Qwen.
To accelerate the training and inference of large models and provide substantial computational support, many companies have developed their own domain-specific architectures (DSA), including NVIDIA GPUs, Huawei Ascend NPUs, Google TPUs, and Cambricon MLUs.
As a representative of these chips, the Ascend NPU has been widely used to support various influential models, such as the Qwen and DeepSeek series, achieving high performance and low power consumption.

% 相较于通用 GPU，Ascend 的特点是额外引入了几种可编程的硬件部件，以高效支撑不同类型的计算：
% 1）计算部件，包括处理控制流、执行指令分发和标量数据计算的 Scalar unit，分别处理向量化和矩阵操作的 Vector 和 Cube Unit。
% 2）多种memory buffer和数据搬运部件：包括面向 Cube Unit 的 L0 A/B/C buffer，以及面向 Vector Unit 的 Unified buffer。这些存储部件之间的数据搬运方式也很灵活，
% 这些硬件部件之间的数据通路我们将在后文中详细介绍，参见xxx.

Compared to general-purpose GPUs, Ascend introduces several additional programmable hardware components to efficiently support different types of computations:
1) Computational components, including the Scalar Unit for handling control flow, instruction dispatch, and scalar data computations, as well as the Vector and Cube Units for processing vectorized and matrix operations, respectively.
2) Various memory buffers and data transfer components: including L0 A/B/C buffers for the Cube Unit and a Unified Buffer for the Vector Unit. The data transfer methods between these storage components are also flexible.

% 上述的设计给开发人员提供了超越 GPU 的可编程性和性能优化潜力，
% 但这也导致 Ascend 核函数的开发者需要更仔细地控制对性能十分重要的并行度以及负载均衡，
% 开发者通常会为算子内的操作定义一组参数，用于控制核函数的每个层级的存储层级上 macro-kernel 的 tile size、迭代顺序、缓冲区数目，以及各个存储层级之间的数据搬运方式。
% 为了支持诸如 Transformer 架构的动态形状模型（输入张量的形状是动态、运行时可变的），上述这组控制参数，连同算子的形状参数、ragged tensor(batch 内 tensor 形状不同)的 offsets 数组、输入输出的数据格式等一起，被实现核函数的形式参数。
% 这些核函数参数需要运行时根据输入形状即时确定再从 Host 传递到 Device，这导致 Scalar Unit 需要实际执行依赖这些参数变量的控制流指令、标量计算并消耗宝贵的通用寄存器（类似于 CPU，每个Davinci Core 核心只有 32 个通用 64 bit 寄存器）存储中间结果。
% 在一类工作负载降低的核函数中，由于 Cube、 Vector 以及数据搬运类的操作次数较少，难以有效掩藏 Scalar Unit 上的任务。
% 尤其是诸如 Flash Decoding （用于 LLM 模型自回归解码阶段执行高效注意力计算）这类工作负载较低、计算逻辑又相对复杂的算子，
% Scalar Unit bound 实际上是这类核函数的一个关键性能瓶颈。

While the above design provides developers with programmability and performance optimization potential beyond GPUs,
it also requires Ascend kernel function developers to carefully control parallelism and load balancing, which are crucial for performance.
Developers typically define a set of parameters for operations within operators to control the tile size of macro-kernels at each level of the memory hierarchy, iteration order, number of buffers, and data transfer methods between different memory levels.
To support dynamic shapes (where input tensor shapes are compile-time unknown and vary at runtime), all these control parameters and shape sizesnm are definded as formal parameters of the implemented kernel functions. 
Besides, to support various Transformer-based model variants with different data formats or 

% , this set of control parameters, along with the operator's shape parameters, offsets arrays for ragged tensors (where tensor shapes differ within a batch), and input/output data formats, are all formal parameters of the implemented kernel functions.

我们统计了 CANNDev、CANN OPS ADV 两个在 Ascend 设备上最广泛使用的算子库的部分算子的各类硬件部件的利用率。
图中纵轴代表算子执行中，一种硬件部件的 active 周期数目。
注意，由于 SIMD 架构的 DSA 多个硬件部件通常并行执行，所有硬件部件的总周期数目实际上大于算子的总执行周期数目。
上图证明 Ascend 的核函数性能对核函数的参数数目敏感，过多的参数可能会导致标量部件成为瓶颈，其他运算和访存部件由于等待标量部件而处于 idle 状态。
进一步地，我们分析发现，固定模型参数（例如注意力头数目、embedding size、最大输入长度等）和硬件配置后，大部分核函数参数都是编译期常量（运行时为不变量且可以在编译期静态求值）。
如表 xxx 所示，这揭示了潜在加速 Ascend 核函数的机会：识别属于编译期常量的核函数参数在编译期替换为常量值，
并通过 DSA native 编译器编译产生针对特定模型和硬件的特化优化的核函数。

据我们所知，当前从 DSA 算子库提取核函数可以被特化的参数的方法主要有两种：
1）对特定的核函数参数执行手工的常量传播；2）基于自动调优 (AutoTuning) 或即时编译确定部分核函数参数。
手工常量传播通常只对少数特定的核函数参数做特化，这种方法预先枚举每个参数的所有可能取值并为每种取值特化生成一个核函数。
这种方式通常只适用于核函数参数较少、手工枚举待特化参数的所有取值不是特别复杂的情况，
由于 GPU 的 SIMT 架构的可编程硬件较少，算子库核函数的参数数目也较少，因而采取了这种方法。
但手工常量特化的不足在于可能会导致严重的代码膨胀问题。
出于泛化性以及减少运行时编译开销的考虑，算子库通常采取 AOT 编译方式，编译前需要适配好各类模型和各种硬件，导致代码和编译产物的基础体积就已经很大了。
因而即便是只枚举部分核函数参数的少量取值，也通常会使代码体积严重增加。
一些 AI Compiler 或者高层张量编程 DSL (Linalg, Triton, etc.) 的算子实现主要通过自动调优 (AutoTuning) 以及即时编译的方式实现自动常量特化核函数的部分参数。
但这种常量特化严重依赖根据运行时形状实际执行 wrapper code 并启用在线常量特化，带来 CPU 上的执行和编译开销。
因而在模型工业部署落地场景中，当前依然以手工算子库为主，AI Compiler 自动生成的算子为辅的方式提供高性能推理服务。

综上原因，我们认为有必要设计一套常量特化框架，实现根据算子的输入形状中的常量维度的取值和算子的 Host code，自动识别出核函数参数中哪些参数是编译时常量，从而实现对核函数的自动常量特化。

针对算子库通常基于 C++ 开发这一事实，本文提出一个基于跨过程常量传播实现的算子自动常量特化方法。
我们的方法可以用于降低算子的推理时延，尤其是降低算子的标量计算开销，也能实现对算子库的代码瘦身，后者在资源受限的端侧设备以及无服务计算上更重要。


在编译时，我们基于深度学习框架（例如 PyTorch Dynamo），运行动态形状模型，捕获得到每个算子的每个输入输出的 symbolic shape 以及算子属性（例如注意力头数目、embedding size）的常量值。
此外，我们手动为硬件构造了一份配置文件，描述了 Host Code 可能会查询的硬件基本信息，例如计算核心数目以及 L1/L2 Cache 的大小等信息。
对于整个算子库，我们将其中的 Host 程序降低到 LLVM IR，我们为每个算子的 Host Code 的入口函数根据前面获取的输入输出形状和算子属性信息，构造一份常量特化的上下文。
基于算子程序 LLVM IR 和常量特化上下文，我们提出一种基于抽象解释的常量传播框架，称作 \mysys 用于推导出核函数的编译期常量的参数值。
动态形状检查在算子程序中普遍存在，针对变量维度及其表达式的条件检查语句会造成多条程序路径，为此我们提出一种识别不可达路径的方法来避免分析精度的降低。
此外，针对 C++ 算子程序中普遍使用的多态类型以及指针，为提升分析精度，我们在抽象解释中引入了指针指向的传播。
此外，当遇到不确定的指针指向时，不同于传统的方法为了保证分析的正确需要将所有可能指向的内存区域都设置为 Unknown，这可能会导致我们的分析对象被污染，我们采取了相当激进的实现：忽略不确定的指针指向，不更新任何内存，我们将正确性的检查留给运行时的正确性检测。
通过上述常量传播，我们可以分析得出核函数的部分参数取值，并将这些参数替换为对应的常量，再对核函数进行常量相关的优化，得到特化的核函数程序。
此外，我们用特化的参数为特化核函数安装一个运行时正确性检测的 guard，确保特化核函数的正确性。
在运行时，对于给定的运行时形状，我们首先运行一遍 guard，若满足约束则调用特化核函数；否则，调用原版非特化的核函数。

